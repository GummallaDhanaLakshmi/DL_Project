{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IUntm1TzqOH"
   },
   "source": [
    "## Deep Learning with PyTorch : Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8oC8O0JzhmG",
    "outputId": "1678c001-0c8f-4634-e580-13bc186e8776"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBRqlDttzhmO"
   },
   "source": [
    "## Task 2 : Loading VGG Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlfO4Dn4zhmP",
    "outputId": "1bf198c0-9350-4b09-eba7-4ab14d627b93"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      4\u001b[0m vgg \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mvgg19(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "vgg = models.vgg19(pretrained=True)\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQduWdGnzhmS",
    "outputId": "8ed70d9f-38f3-45ae-ffec-9b9b76590290"
   },
   "outputs": [],
   "source": [
    "vgg = vgg.features\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rg0tgeEozhmW"
   },
   "outputs": [],
   "source": [
    "for parameters in vgg.parameters():\n",
    "  parameters.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WX91rnk_zhma",
    "outputId": "25e6470b-b7cd-4fb0-f7d0-6ebc10219faf"
   },
   "outputs": [],
   "source": [
    "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pol6UHaeoHA_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukKfc2-MoJwZ",
    "outputId": "e8778289-34be-427e-f19b-c662efc82866"
   },
   "outputs": [],
   "source": [
    "vgg.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxM2YyaVzhmd"
   },
   "source": [
    "## Task 3 : Preprocess image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRJZpXiAxb9l"
   },
   "source": [
    "Torchvision models page : https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7szQ02nzhme"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "def preprocess(img_path,max_size=500):\n",
    "  image=Image.open(img_path).convert('RGB')\n",
    "  if max(image.size) > max_size:\n",
    "    size=max_size\n",
    "  else:\n",
    "    size=max(image.size)\n",
    "  img_transforms=T.Compose([\n",
    "      T.Resize(size),\n",
    "      T.ToTensor(),\n",
    "      T.Normalize(mean =[0.485,0.456,0.406 ],\n",
    "                  std=[0.229,0.224,0.225])\n",
    "\n",
    "\n",
    "      ])\n",
    "  image=img_transforms(image)\n",
    "  image=image.unsqueeze(0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osMP6zX4zhmh",
    "outputId": "df5b070b-97dd-4a14-fb5c-07022141c8a1"
   },
   "outputs": [],
   "source": [
    "content_p=preprocess('/content/free-images.jpg')\n",
    "style_p=preprocess('/content/color.jpg')\n",
    "content_p =content_p.to(device)\n",
    "style_p=style_p.to(device)\n",
    "print(\"Content shape\",content_p.shape)\n",
    "print(\"Style shape\",style_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylW3-U354e8k"
   },
   "source": [
    "## Task 4 : Deprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHOZgcQnzhmk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def deprocess( tensor):\n",
    "  image=tensor.to('cpu').clone()\n",
    "  image=image.numpy()\n",
    "  image=image.squeeze(0)\n",
    "  image=image.transpose(1,2,0)\n",
    "  image=image*np.array([0.229,0.224,0.225])+np.array([0.485,0.456,0.406 ])\n",
    "  image=image.clip(0,1)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uleFVOuyzhmo",
    "outputId": "389da494-28e6-40b0-ee93-2e8fa550be17"
   },
   "outputs": [],
   "source": [
    "content_d=deprocess(content_p)\n",
    "style_d =deprocess(style_p)\n",
    "print(\"deprocess content:\",content_d.shape)\n",
    "print(\"deprocess style:\",style_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "AZgD9y_Kzhmr",
    "outputId": "0d85588b-fe9b-471f-90bf-96824847edb6"
   },
   "outputs": [],
   "source": [
    "fig , (ax1,ax2)=plt.subplots(1,2,figsize=(20,10))\n",
    "ax1.imshow(content_d)\n",
    "ax2.imshow(style_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vohyJ0Eizhmu"
   },
   "source": [
    "## Task 5 : Get content,style features and create gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48e6BNHGzhmv"
   },
   "outputs": [],
   "source": [
    "def get_features(image, model):\n",
    "    layers = {\n",
    "        '0': 'conv1_1',\n",
    "        '5': 'conv2_1',\n",
    "        '10': 'conv3_1',\n",
    "        '19': 'conv4_1',\n",
    "        '21': 'conv4_2',\n",
    "        '28': 'conv5_1'\n",
    "    }\n",
    "    x = image\n",
    "    Features = {}\n",
    "    for name, layer in model._modules.items():\n",
    "        x = layer(x)\n",
    "        if name in layers:\n",
    "            Features[layers[name]] = x\n",
    "    return Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1PhbsKizhmy"
   },
   "outputs": [],
   "source": [
    "content_f=get_features(content_p,vgg)\n",
    "style_f=get_features(style_p,vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxp17pv5zhm2"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "  b,c,h,w=tensor.size()\n",
    "  tensor = tensor.view(c,h*w)\n",
    "  gram = torch.mm(tensor,tensor.t())\n",
    "  return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSrDvJsTVuyg"
   },
   "outputs": [],
   "source": [
    "style_grams={layer :gram_matrix(style_f[layer]) for layer in style_f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYG8nmYnzhm6"
   },
   "source": [
    "## Task 6 : Creating Style and Content loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8bZVJGGzhm6"
   },
   "outputs": [],
   "source": [
    "def content_loss(target_conv4_2,content_conv4_2):\n",
    "  loss= torch.mean((target_conv4_2-content_conv4_2)**2)\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4dUvmSwzhm-"
   },
   "outputs": [],
   "source": [
    "style_weights={\n",
    "    'conv1_1':1.0,\n",
    "    'conv2_1':0.75,\n",
    "    'conv3_1':0.2,\n",
    "    'conv4_1':0.2,\n",
    "    'conv5_1':0.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RYWY5EnzhnB"
   },
   "outputs": [],
   "source": [
    "def style_loss(style_weights,target_features,style_grams):\n",
    "  loss =0\n",
    "  for layer in style_weights:\n",
    "    target_f=target_features[layer]\n",
    "    target_gram=gram_matrix(target_f)\n",
    "    style_gram=style_grams[layer]\n",
    "    b,c,h,w =target_f.shape\n",
    "    layer_loss=style_weights[layer]*torch.mean((target_gram-style_gram)**2)\n",
    "    loss+=layer_loss/(c*h*w)\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JnlDE1kPbCw",
    "outputId": "ebb0b299-ce3d-4b16-f158-dc458af043cd"
   },
   "outputs": [],
   "source": [
    "target=content_p.clone().requires_grad_(True).to(device)\n",
    "target_f=get_features(target,vgg)\n",
    "print(target_f.keys())\n",
    "\n",
    "print(\"contentloss :\", content_loss(target_f['conv4_2'], content_f['conv4_2']))\n",
    "\n",
    "print(\"style loss  : \",style_loss(style_weights,target_f,style_grams))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHF2xVr1zhnE"
   },
   "source": [
    "## Task 7 : Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OalABhfjzhnF"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer=optim.Adam([target],lr=0.003)\n",
    "\n",
    "alpha=1\n",
    "beta=1e5\n",
    "\n",
    "epochs=3000\n",
    "show_every=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDFL71FQzhnI"
   },
   "outputs": [],
   "source": [
    "def total_loss(c_loss,s_loss,alpha,beta):\n",
    "  loss=alpha*c_loss+beta*s_loss\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmjKkgBhzhnO",
    "outputId": "872ae0bc-1bbf-4049-fcec-5a1275fcdd9c"
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(epochs):\n",
    "  target_f=get_features(target,vgg)\n",
    "  c_loss=content_loss(target_f['conv4_2'],content_f['conv4_2'])\n",
    "  s_loss=style_loss(style_weights,target_f,style_grams)\n",
    "  t_loss=total_loss(c_loss,s_loss,alpha,beta)\n",
    "  optimizer.zero_grad()\n",
    "  t_loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if i %show_every==0:\n",
    "    print('total loss at epoch {}:{}'.format(i,t_loss))\n",
    "    results.append(deprocess(target.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "PGzdEJt_UAr9",
    "outputId": "8a2e5abc-6786-4c17-e2ab-fe51b2d2208e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for i in range(len(results)):\n",
    "  plt.subplot(3,2,i+1)\n",
    "  plt.imshow(results[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "Q8EE7JGKZ_8X",
    "outputId": "79847f30-d430-4ede-9757-94240076910b"
   },
   "outputs": [],
   "source": [
    "target_copy =deprocess(target.detach())\n",
    "content_copy=deprocess(content_p)\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "ax1.imshow(target_copy)\n",
    "ax2.imshow(content_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
